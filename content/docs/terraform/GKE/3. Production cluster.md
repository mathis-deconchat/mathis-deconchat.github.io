---
title: "3. Production Cluster"
date: 2023-08-23T11:28:46+02:00
draft: false
icon: "code_blocks"
weight: 1200
description: "Create a production ready cluster with Terraform"

---
## Production cluster
{{< alert context="info" text="You'll find many ressources online on this way to create a cluster. The following code is heavily inspired by [Hashicorp GKE](https://developer.hashicorp.com/terraform/tutorials/kubernetes/gke)"/>}}
### Intro
In this cluster, we will create the VPC (Virtual Private Cloud) and the subnetworks where the nodes will be deployed. If not specified, like the minimalist cluster, the nodes will be deployed in the default VPC and subnetworks. The reason why we create a new VPC is that we don't want to use the default one since it's shared with other users. We want to have our own VPC to be able to configure it as we want.
We will also create separate node pools, to be able to update nodes without restarting the whole cluster.

Create a new folder or erase the content of the `main.tf` from before.
Create the following file structure:
```bash
touch vpc.tf node-pool.tf variables.tf var.tfvars provider.tf backend.tf gke.tf
```
### State management
In the minimalist cluster example, the state was stored locally. It's not a good practice since it's not shared between the team. We will use a remote backend to store the state in a bucket on GCP.

First activate the API of Google Cloud Storage (GCS)
```bash
gcloud services enable storage.googleapis.com
```
Create a bucket to store the state of our infra. 

{{< alert context="info" text="The bucket name must be unique (on all GCP), so change the name in the following command" />}}
I'll add part of my project ID to the name to be sure it's unique.
```bash
gcloud storage buckets create gs://tf-state-gke-396804 --project tf-gke-396804 --location europe-west9
```
The output should be something like this:
```bash
Creating gs://tf-state-gke-396804/...
``` 
We also need object versionning on our bucket, so we can be able to restore a previous state if needed.
```bash
gcloud storage buckets update gs://tf-state-gke-396804 --versioning 
```
Output : 
```bash
Updating gs://tf-state-gke-396804/...                                       
  Completed 1   
```

Once done, add the following code to `backend.tf` and obviously change the bucket name with yours
```hcl
terraform {
 backend "gcs" {
   bucket  = {BUCKET_NAME}
   prefix  = "terraform/state/realworld"
 }
}
```

### Variables 
First, we need to declare our variables. In the `variables.tf` file, add the following code:
```hcl
variable "project_id" {
  description = "project id"
  type = string  
}

variable "region" {
  description = "region"
  type = string
}

variable "gke_node_count" {
  description = "number of nodes in the GKE cluster"
  type = number
  default = 1
}
```

And in `var.tfvars`, add the following code
(Replace the values with yours):
```hcl
project_id = "tf-gke-396804"
region = "europe-west9"
gke_node_count = 3
```
### Provider
We need to add the provider for GCP. In the `provider.tf` file, add the following code:
```hcl
terraform {
  required_providers {
    google = {
      source = "hashicorp/google"
      version = "4.79.0"
    }
  }
}

provider "google" {
  project = var.project_id
  region  = var.region
}
```
Since the *"2. Minimalist cluster"* part, we have generated credentials to be able to use the GCP API via Terraform. In a future part, we will  create a service account and use it when instancing the provider. For now, we will use the credentials we have generated before.

### VPC
First, we need to create a new VPC. In the `vpc.tf` file, add the following code:
```hcl
resource "google_compute_network" "vpc" {
  name                    = "${var.project_id}-vpc"
  auto_create_subnetworks = "false"
}
```

And then the subnet attached to the VPC. It will be the subnet where the nodes will be deployed. In the `vpc.tf` file, add the following code:
```hcl
resource "google_compute_subnetwork" "subnet" {
  name          = "${var.project_id}-subnet"
  region        = var.region
  network       = google_compute_network.vpc.name
  ip_cidr_range = "10.10.0.0/24"
}
``` 

### Cluster
First, we will define the cluster, even if the order has no importance. In the `gke.tf` file, add the following code:
```hcl {linenos=table, hl_lines=[5,6]}
resource "google_container_cluster" "primary" {
  name     = "${var.project_id}-gke"
  location = var.region

  remove_default_node_pool = true
  initial_node_count       = 1

  network    = google_compute_network.vpc.name
  subnetwork = google_compute_subnetwork.subnet.name
}
```
The highlighted lines are the ones that are important. We remove the default node pool and we create a new one with only one node. We will create our pwn node pool. That's the way the provider recommend to do it.

### Node pool
Now we will create our node pool. In the `node-pool.tf` file, add the following code:
```hcl {linenos=table}
resource "google_container_node_pool" "primary_nodes" {
  name       = "${var.project_id}-gke"
  cluster    = google_container_cluster.primary.id
  node_count = var.gke_node_count

  node_config {
    preemptible  = true
    machine_type = "e2-medium"

    labels = {
      env = var.project_id
    }

    # Google recommends custom service accounts that have cloud-platform scope and permissions granted via IAM Roles.
    oauth_scopes = [
      "https://www.googleapis.com/auth/cloud-platform"
    ]
  }
}
```
In `cluster`, we pass a reference to the cluster we created brefore. Since it's a dependency, Terraform will always create the cluster first then the node pool.

### Launching terraform ðŸš€ !
Your directory stucture should look like this:
```bash
.
â”œâ”€â”€ backend.tf
â”œâ”€â”€ gke.tf
â”œâ”€â”€ node-pool.tf
â”œâ”€â”€ provider.tf
â”œâ”€â”€ var.tfvars
â”œâ”€â”€ variables.tf
â””â”€â”€ vpc.tf
``` 

Now we can launch terraform. First, we need to initialize it:
```bash
tf init
```
Then we can check what terraform will do:
```bash
tf plan -var-file=var.tfvars
```
And finally, we can apply the changes:
```bash
tf apply -var-file=var.tfvars -auto-approve
```

After 5-10 minutes, the cluster should be created. You can check it. 
```bash
gcloud container clusters list
```

And also check the nodes:
```bash
gcloud compute instances list
```

And finally check the node pool we created:
```bash
gcloud container node-pools list --cluster {CLUSTER_NAME}
```








